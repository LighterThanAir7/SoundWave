CREATE TABLE users (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    id_type int(10) NOT NULL,
    status tinyint(1) DEFAULT 1,
    email varchar(255) NOT NULL UNIQUE,
    firstname varchar(50),
    lastname varchar(50),
    base_username varchar(50) NOT NULL,
    discriminator varchar(4) NOT NULL,
    password varchar(255) NOT NULL,
    img varchar(255),
    date_birth date,
    sex char(1),
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    last_login timestamp NULL,
    FOREIGN KEY (id_type) REFERENCES spt_user_type(id),
    UNIQUE KEY unique_username (base_username, discriminator)
);

CREATE TABLE spt_user_type (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    status tinyint(1) DEFAULT 1,
    name varchar(50) NOT NULL UNIQUE,
    description varchar(255)
);

-- Insert default user types
INSERT INTO spt_user_type (name, description) VALUES
('Super Administrator', 'Has complete control over the system with all privileges'),
('Administrator', 'Has administrative access with limited system configuration abilities'),
('User', 'Regular user with basic access privileges');


CREATE TABLE api_keys (
    id            int auto_increment primary key,
    key_name      varchar(255) not null UNIQUE,
    encrypted_key text not null,
    created_at    timestamp default current_timestamp() not null,
    last_used     timestamp null,
    is_active     tinyint(1) default 1 null
);


CREATE TABLE artists (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    name varchar(255) NOT NULL UNIQUE,
    bio text,
    image_url varchar(255),
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

CREATE TABLE albums (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    title varchar(255) NOT NULL,
    release_date date,
    total_tracks int,
    cover_art_url varchar(255),
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

CREATE TABLE songs (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    title varchar(255) NOT NULL,
    primary_artist_id int(10) NOT NULL,
    album_id int(10),
    duration int NOT NULL,
    track_number int,
    released_on date,
    artwork_path varchar(255),
    file_path varchar(255) NOT NULL,
    file_format varchar(10) NOT NULL,
    file_size bigint NOT NULL,
    bitrate int NOT NULL,
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (primary_artist_id) REFERENCES artists(id),
    FOREIGN KEY (album_id) REFERENCES albums(id)
);

CREATE TABLE genres (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    name varchar(255) NOT NULL UNIQUE,
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

CREATE TABLE song_genre (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    song_id int(10) NOT NULL,
    genre_id int(10) NOT NULL,
    FOREIGN KEY (song_id) REFERENCES songs(id),
    FOREIGN KEY (genre_id) REFERENCES genres(id)
);

CREATE TABLE collaborating_artists (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    song_id int(10) NOT NULL,
    artist_id int(10) NOT NULL,
    artist_role varchar(50),
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (song_id) REFERENCES songs(id),
    FOREIGN KEY (artist_id) REFERENCES artists(id)
);

CREATE TABLE playlists (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    name varchar(255) NOT NULL,
    user_id int(10) NOT NULL,
    description text,
    is_public boolean DEFAULT false,
    image_url varchar(255),
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

CREATE TABLE playlist_songs (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    playlist_id int(10) NOT NULL,
    song_id int(10) NOT NULL,
    order_number int NOT NULL,
    added_by_user_id int(10) NOT NULL,
    added_on timestamp DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY unique_playlist_song (playlist_id, song_id),
    FOREIGN KEY (playlist_id) REFERENCES playlists(id),
    FOREIGN KEY (song_id) REFERENCES songs(id),
    FOREIGN KEY (added_by_user_id) REFERENCES users(id)
);


























Would you like to implement any additional features like:

    Token refresh mechanism
    Remember me functionality
    Secure logout endpoint
    Session timeout handling


Regarding the naming convention, _on is indeed more intuitive for datetime fields as it indicates "when" something happened, while _at is more commonly used for timestamps in some frameworks. For artwork handling, storing the file path is definitely better than base64 in the database. You could:

    Extract artwork from MP3
    Save it as a separate file
    Store only the path in the database
    Use the embedded artwork as fallback if file is missing

-- For likes/favorites
CREATE TABLE user_song_interactions (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    user_id int(10) NOT NULL,
    song_id int(10) NOT NULL,
    is_favorite boolean DEFAULT false,
    play_count int DEFAULT 0,
    last_played timestamp,
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY unique_user_song (user_id, song_id),
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (song_id) REFERENCES songs(id)
);

-- For song lyrics (optional)
CREATE TABLE lyrics (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    song_id int(10) NOT NULL UNIQUE,
    text text NOT NULL,
    language varchar(5) DEFAULT 'en',
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (song_id) REFERENCES songs(id)
);
-- For play history
CREATE TABLE play_history (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    user_id int(10) NOT NULL,
    song_id int(10) NOT NULL,
    played_at timestamp DEFAULT CURRENT_TIMESTAMP,
    played_duration int, -- in seconds, to track if song was played partially
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (song_id) REFERENCES songs(id),
    INDEX idx_user_played (user_id, played_at)
);

-- For user activity logging
CREATE TABLE user_activity (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    user_id int(10) NOT NULL,
    activity_type ENUM('PLAY', 'LIKE', 'CREATE_PLAYLIST', 'ADD_TO_PLAYLIST', 'FOLLOW_ARTIST', 'RATE'),
    entity_type ENUM('SONG', 'PLAYLIST', 'ARTIST', 'ALBUM'),
    entity_id int(10) NOT NULL,
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    INDEX idx_user_activity (user_id, created_on)
);

-- For ratings
CREATE TABLE ratings (
    id int(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,
    user_id int(10) NOT NULL,
    entity_type ENUM('SONG', 'ALBUM', 'PLAYLIST'),
    entity_id int(10) NOT NULL,
    rating tinyint NOT NULL CHECK (rating BETWEEN 1 AND 5),
    created_on timestamp DEFAULT CURRENT_TIMESTAMP,
    updated_on timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    UNIQUE KEY unique_user_rating (user_id, entity_type, entity_id),
    FOREIGN KEY (user_id) REFERENCES users(id),
    INDEX idx_entity (entity_type, entity_id)
);

Based on the search results, detecting duplicate audio files requires sophisticated audio fingerprinting that can identify similar songs even with differences in:

    Audio quality and bitrate1
    File length (slightly shorter or longer versions)1
    Volume levels and audio filtering1
    File formats (MP3, AAC, FLAC, etc.)1
    3
    Metadata/ID3 tags3

For your implementation, you could:

    Use audio fingerprinting algorithms to analyze the actual audio content rather than just metadata4
    Compare audio files based on sound content rather than binary patterns6
    Set similarity thresholds to control how strict the matching should be1

Matching Criteria

    Duration differences
    Bitrate variations
    Volume differences
    Audio filtering and noise
    File format conversions

This would help identify duplicates even when:

    Files have different names
    Songs are in different formats
    Audio quality varies
    Length slightly differs
    Volume levels are different

Would you like me to show how to implement audio fingerprinting in your current upload system?


!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


    Add progress tracking for large uploads:

javascript
const handleBatchUpload = async (event) => {
    event.preventDefault();
    if (!selectedBatchFiles) return;

    const files = Array.from(selectedBatchFiles).filter(
        file => file.type === 'audio/mpeg'
    );

    const formData = new FormData();
    files.forEach(file => formData.append('files', file));

    setUploading(true);

    try {
        const response = await fetch(`${API_URL}/api/upload/songs/batch`, {
            method: 'POST',
            body: formData,
            onUploadProgress: (progressEvent) => {
                const percentCompleted = Math.round(
                    (progressEvent.loaded * 100) / progressEvent.total
                );
                setProgress(percentCompleted);
            }
        });

        // ... rest of the code
    }
};

    Add server-side chunking and progress updates:

javascript
export const handleBatchSongUpload = async (req, res) => {
    try {
        const totalFiles = req.files.length;
        const processedFiles = [];
        const errors = [];
        let processed = 0;

        for (const file of req.files) {
            try {
                const tags = NodeID3.read(file.path);
                processedFiles.push({
                    filename: file.filename,
                    path: file.path,
                    metadata: tags
                });

                // Update progress every 100 files
                processed++;
                if (processed % 100 === 0) {
                    // If using WebSocket or Server-Sent Events
                    // emit progress update
                    console.log(`Processed ${processed}/${totalFiles} files`);
                }
            } catch (error) {
                errors.push({
                    filename: file.originalname,
                    error: error.message
                });
            }
        }

        res.json({
            message: 'Batch upload processed',
            totalFiles,
            successfulUploads: processedFiles.length,
            failedUploads: errors.length,
            processedFiles,
            errors
        });

    } catch (error) {
        console.error('Batch upload error:', error);
        res.status(500).json({
            message: 'Error processing batch upload',
            error: error.message
        });
    }
};

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Recommendations:

    Set limit to 5000 files initially (can be adjusted based on testing)
    Add proper progress tracking
    Implement chunked processing
    Add server-side progress updates
    Consider implementing resume capability for failed uploads
    Add proper error handling for timeouts
    Consider implementing WebSocket or SSE for real-time progress updates
